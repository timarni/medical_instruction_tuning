{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 -> Multiturn conversation dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "import random\n",
    "import pandas as pd\n",
    "from multiturn_modul import MultiturnStyle, get_multiturn_style\n",
    "\n",
    "path_to_api_key: str = \"../API_KEY.txt\"\n",
    "my_api_key = open(path_to_api_key, 'r').read()\n",
    "client = OpenAI(api_key=my_api_key)\n",
    "gpt_model: str = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a medical AI chatbot designed to assist health care workers working in Switzerland by answering their questions. \n",
      "The style of your answers must follow these rules: \n",
      "Provide short and concises answers. \n",
      "Provide your answers in flat text. \n",
      "\n",
      "You are a physician working in Switzerland using a medical AI chatbot to help you taking care of your patients. \n",
      "The initial question that you ask the medical AI chatbot has already been provided. You are now interacting with the medical AI chatbot and asking follow up questions, based on the answers provided by the medical AI chatbot. \n",
      "The style of the follow up question you ask must follow these rules: \n",
      "Ask short and concises questions. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "countries = pd.read_csv(\"../resources/countries_by_income_category.csv\")\n",
    "sampled_country = random.choice(countries.iloc[:, 0].tolist())\n",
    "id = \"0-122\"\n",
    "\n",
    "for i in range(10000):\n",
    "    test = get_multiturn_style(str(i%12)+\"-112\", \"Switzerland\")\n",
    "\n",
    "multiturn_style_1 = MultiturnStyle(id, sampled_country, nbr_of_turns=2, mode = \"normal\")\n",
    "\n",
    "print(multiturn_style_1.system_prompt_chatbot())\n",
    "print(multiturn_style_1.system_prompt_user())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"How can I explain the basics of BRCA1 and BRCA2 gene mutations and their implications for breast cancer risk in simple terms to help my patient understand their recent genetic test results?\"\n"
     ]
    }
   ],
   "source": [
    "# Test mode\n",
    "# Generate multiturn conversations between Meditron (simulated by gpt-4o) and a Physician (simulated by gpt-4o)\n",
    "\n",
    "# System prompts\n",
    "system_prompt_chatbot = multiturn_style_1.system_prompt_chatbot()  + \"In the prompt you see the whole chat history. You are (chatbot). Your task is to answer the questions and only ask follow up questions, if the user did not provide enough information in its input.\"\n",
    "system_prompt_user = multiturn_style_1.system_prompt_user()  + \"In the prompt you see the whole chat history. You are (user). You want to get an answer to the first question you asked. Your task is to ask followup questions and to interact with the chatbot to get a clear answer to your initial, as a health care worker would do.\"\n",
    "system_prompt_chatbot += \"\\nYour (chatbot) tag is added manually, don't write it in your output. Just generate an answer to the users input\"\n",
    "system_prompt_user += \"\\nYour (user) tag is added manually, don't write it in your output. Just generate a question or an instruction for the chatbot, based on the conversation history\"\n",
    "\n",
    "# store medical AI tasks in a list\n",
    "path_to_prompts = \"../results/parsed_prompts_tasks_x_subtopics_part2.json\" \n",
    "with open(path_to_prompts, 'r') as file:\n",
    "    task_x_subtopics_prompts = json.load(file)  # Load JSON data from file\n",
    "initial_physician_prompt = task_x_subtopics_prompts[5000][\"prompt\"]\n",
    "print(initial_physician_prompt)\n",
    "\n",
    "# Function that generates the next step of a conversation\n",
    "\n",
    "def next_conversation_step(system_prompt, chat_histroy, verbose = False):\n",
    "    if system_prompt == \"user\":\n",
    "        content = system_prompt_user\n",
    "    else:\n",
    "        content = system_prompt_chatbot\n",
    "\n",
    "    prompt = chat_histroy\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Send prompt to GPT:\")\n",
    "        print(\"#########\")\n",
    "        print(prompt)\n",
    "        print(\"########\")\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model= gpt_model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": content},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"{prompt}\"\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    response = completion.choices[0].message.content\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Receiving responses from GPT...\")\n",
    "        print(response)\n",
    "    return chat_histroy + \"\\n\" + f\"({system_prompt}) \" + response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "chatbot: You are a medical AI chatbot designed to assist health care workers working in Switzerland by answering their questions. \n",
      "The style of your answers must follow these rules: \n",
      "Provide short and concises answers. \n",
      "Provide your answers in flat text. \n",
      "In the prompt you see the whole chat history. You are (chatbot). Your task is to answer the questions and only ask follow up questions, if the user did not provide enough information in its input.\n",
      "Your (chatbot) tag is added manually, don't write it in your output. Just generate an answer to the users input\n",
      "user: You are a physician working in Switzerland using a medical AI chatbot to help you taking care of your patients. \n",
      "The initial question that you ask the medical AI chatbot has already been provided. You are now interacting with the medical AI chatbot and asking follow up questions, based on the answers provided by the medical AI chatbot. \n",
      "The style of the follow up question you ask must follow these rules: \n",
      "Ask short and concises questions. \n",
      "In the prompt you see the whole chat history. You are (user). You want to get an answer to the first question you asked. Your task is to ask followup questions and to interact with the chatbot to get a clear answer to your initial, as a health care worker would do.\n",
      "Your (user) tag is added manually, don't write it in your output. Just generate a question or an instruction for the chatbot, based on the conversation history\n"
     ]
    }
   ],
   "source": [
    "# Check if everything is fine\n",
    "N = multiturn_style_1.number_of_turns\n",
    "print(N)\n",
    "print(f\"chatbot: {system_prompt_chatbot}\")\n",
    "print(f\"user: {system_prompt_user}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:04<00:00,  1.57s/it]\n"
     ]
    }
   ],
   "source": [
    "conversation_history = []\n",
    "conversation_history.append(\"(user) \" + initial_physician_prompt)\n",
    "for i in tqdm(range(2*N - 1)): ### Change range -> will cost money\n",
    "    if i % 2 == 0:\n",
    "        conversation_history.append(next_conversation_step(\"chatbot\", conversation_history[-1]))\n",
    "    else:\n",
    "        conversation_history.append(next_conversation_step(\"user\", conversation_history[-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(user) \"How can I explain the basics of BRCA1 and BRCA2 gene mutations and their implications for breast cancer risk in simple terms to help my patient understand their recent genetic test results?\"\n",
      "(chatbot) BRCA1 and BRCA2 are genes that help repair DNA. When they have harmful mutations, this repair process can be impaired, increasing the risk of breast and ovarian cancer. People with these mutations have a higher chance of developing these cancers compared to the general population. Early detection and preventive strategies can help manage this risk.\n",
      "(user) What preventive strategies can be recommended?\n",
      "(chatbot) Preventive strategies include regular breast cancer screening like mammograms and MRI, lifestyle changes such as maintaining a healthy weight and limiting alcohol, and medications like tamoxifen or raloxifene for risk reduction. Surgical options, such as prophylactic mastectomy or oophorectomy, may also be considered for high-risk individuals. Discuss personalized recommendations with a healthcare professional.\n"
     ]
    }
   ],
   "source": [
    "print(conversation_history[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ihlqa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
