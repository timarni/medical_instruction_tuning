{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 -> medical_ai_tasks x specialties x demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from multiturn_modul import MultiturnStyle, get_multiturn_style\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batch of prompts\n",
    "\n",
    "# Specify which model should be used to answer prompts\n",
    "gpt_model = \"gpt-4o\"\n",
    "\n",
    "# Path for input data and to store prompts\n",
    "medical_ai_tasks_file = \"../resources/medical_ai_tasks.json\"\n",
    "medical_professions_file = \"../resources/patient_age_medical_profession.json\"\n",
    "medical_topics_file = \"../resources/medical_topics.json\"\n",
    "age_ranges_file = \"../resources/age_categories.json\"\n",
    "sex_and_gender_file = \"../resources/sex_and_gender.json\"\n",
    "countries_file = \"../resources/countries_by_income_category.csv\"\n",
    "output_path = \"../results/batched_prompts_task_x_specialties_x_demographic.jsonl\"\n",
    "\n",
    "# store medical AI tasks in a list\n",
    "with open(medical_ai_tasks_file, 'r') as file:\n",
    "    medical_ai_tasks = json.load(file)  # Load JSON data from file\n",
    "\n",
    "# store specialties in a list\n",
    "with open(medical_professions_file, 'r') as file:\n",
    "    professions_data = json.load(file)  # Load JSON data from file  \n",
    "\n",
    "# store specialties in a list\n",
    "with open(medical_topics_file, 'r') as file:\n",
    "    topics_data = json.load(file)  # Load JSON data from file  \n",
    "\n",
    "# store age ranges in a list\n",
    "with open(age_ranges_file, 'r') as file:\n",
    "    age_ranges = json.load(file)  # Load JSON data from file\n",
    "\n",
    "# store sex and gender in a list\n",
    "with open(sex_and_gender_file, 'r') as file:\n",
    "    sex_and_gender = json.load(file)  # Load JSON data from file\n",
    "\n",
    "countries = pd.read_csv(countries_file)\n",
    "\n",
    "# prompt and context\n",
    "content = \"You are an assistant responsible for creating prompts that healthcare workers would ask a medical AI chatbot.\"\n",
    "def get_prompt(task, description, additional_instruction, demographics, profession=\"physician\", specialty=\"no\", topic=\"no\"):\n",
    "    prompt_parts = []\n",
    "    prompt_parts.append(f\"Generate a prompt that a {profession} \")\n",
    "    if specialty != \"no\":\n",
    "        prompt_parts.append(f\"specializing in {specialty} and \")\n",
    "    prompt_parts.append(f\"working in {demographics[\"country\"]} \")\n",
    "    prompt_parts.append(f\"might ask an AI chatbot when tasked with {task} \")\n",
    "    if topic != \"no\":\n",
    "        prompt_parts.append(f\"in the context of the medical field \\\"{topic}\\\".\\n\")\n",
    "    else:\n",
    "        prompt_parts.appemd(f\".\\n\")\n",
    "    prompt_parts.append(f\"{task} is described as: {description}\\n\")\n",
    "    prompt_parts.append(f\"To create a realistic prompt, follow these additional instructions: {additional_instruction}\\n\")\n",
    "    prompt_parts.append(f\"The question you generate has to be about a patient with the following demographic attributes:\")\n",
    "    prompt_parts.append(f\"age: {demographics[\"age\"]}\\n\")\n",
    "    prompt_parts.append(f\"sex: {demographics[\"sex\"]}\\n\")\n",
    "    prompt_parts.append(f\"gender: {demographics[\"gender\"]}\\n\")\n",
    "    prompt_parts.append(\"Only include the generated prompt, adding extra details only if specified. Focus solely on a realistic prompt a physician might ask a medical AI chatbot.\")\n",
    "    prompt = \"\".join(prompt_parts)\n",
    "    return prompt\n",
    "\n",
    "def fill_line(prompt_id, gpt_model, content, prompt, max_tokens):\n",
    "    line = {\n",
    "        \"custom_id\": prompt_id,\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": gpt_model,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": content},\n",
    "                {\"role\": \"user\", \"content\": f\"{prompt}\"}\n",
    "            ],\n",
    "            \"max_tokens\": max_tokens\n",
    "        }\n",
    "    }\n",
    "    return line\n",
    "\n",
    "def get_countries(countries_df, nbr_samples):\n",
    "    # Step 1: Group by 'Income Category'\n",
    "    groups = countries_df.groupby(\"Income Category\")\n",
    "\n",
    "    # Step 2: Ensure at least two groups are available\n",
    "    if len(groups) < nbr_samples:\n",
    "        raise ValueError(\"Not enough unique income categories to sample from.\")\n",
    "\n",
    "    # Step 3: Randomly sample one country from two different categories\n",
    "    sampled_countries = []\n",
    "    for category, group in groups:\n",
    "        sampled_countries.append(group.sample(n=1))\n",
    "    sampled_countries_df = pd.concat(sampled_countries).reset_index(drop=True).sample(nbr_samples)\n",
    "    return sampled_countries_df[\"Country\"].to_list()\n",
    "\n",
    "def get_ages(age_categories, possible_ages, nbr_sample):\n",
    "    all_ages = [dict[\"category\"] for dict in age_categories]\n",
    "    if possible_ages[0] == \"All age categories\":\n",
    "        possible_ages = all_ages\n",
    "    ages = random.choices(possible_ages, k=nbr_sample)\n",
    "\n",
    "def adjust_ages(possible_ages):\n",
    "    adjusted_possible_ages = possible_ages\n",
    "        # special cases\n",
    "    if \"Pediatrics\" \"->infants, toddlers, children, and adolescents.\"\n",
    "    if \"Geriatrics\" \"->older adults, elderly, and centenarians.\"\n",
    "    if \"Neonatology\" \"-> infants (newborns).\"\n",
    "    if \"Pain Management\" \"->adults, middle-aged, older adults, and elderly due to chronic pain conditions.\"\n",
    "    if \"Physical Medicine and Rehabilitation\" \"->adults, middle-aged, and older populations\"\n",
    "    if \"Occupational Health\" \"->young adults to middle-aged adults\"\n",
    "    return adjusted_possible_ages\n",
    "\n",
    "def get_sex_gender():\n",
    "        if \"Urology\" ==\n",
    "    if \"Obstetrics and Gynecology\" ==\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_demographics(countries_df, age_categories, possible_ages, nbr_samples, domain=\"no\", specialty=\"no\"):\n",
    "    adjusted_possible_ages = adjust_ages(possible_ages, domain)\n",
    "    countries = get_countries(countries_df, nbr_samples)\n",
    "    ages = get_ages(age_categories, adjusted_possible_ages, nbr_samples)\n",
    "    sex, gender = get_sex_gender(sex_and_gender, specialty)\n",
    "\n",
    "    list_of_patients = []\n",
    "    for i in nbr_samples:\n",
    "        dict = {}\n",
    "        dict[\"country\"] = countries[i]\n",
    "        dict[\"age\"] = ages[i]\n",
    "        dict[\"sex\"] = sex[i]\n",
    "        dict[\"gender\"] = gender[i]\n",
    "\n",
    "    return list_of_patients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Nurse', 'specialties': [['Critical Care Nursing', ['All age categories']], ['Emergency Nursing', ['All age categories']], ['Geriatric Nursing', ['Older Adults', 'Elderly', 'Centenarians']], ['Medical-Surgical Nursing', ['All age categories']], ['Neonatal Nursing', ['Infants']], ['Oncology Nursing', ['All age categories']], ['Pediatric Nursing', ['Infants', 'Toddlers', 'Preschoolers', 'School-age Children', 'Adolescents']], ['Psychiatric Nursing', ['All age categories']], ['Public Health Nursing', ['All age categories']]]}\n",
      "Nurse\n",
      "[['Critical Care Nursing', ['All age categories']], ['Emergency Nursing', ['All age categories']], ['Geriatric Nursing', ['Older Adults', 'Elderly', 'Centenarians']], ['Medical-Surgical Nursing', ['All age categories']], ['Neonatal Nursing', ['Infants']], ['Oncology Nursing', ['All age categories']], ['Pediatric Nursing', ['Infants', 'Toddlers', 'Preschoolers', 'School-age Children', 'Adolescents']], ['Psychiatric Nursing', ['All age categories']], ['Public Health Nursing', ['All age categories']]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating a batch of prompts\")\n",
    "print(f\"that can be processed by {gpt_model} in batch mode\")\n",
    "\n",
    "id = 0\n",
    "with open(output_path, 'w') as file:\n",
    "    for medical_ai_task in tqdm(medical_ai_tasks):\n",
    "        task = medical_ai_task[\"task\"]\n",
    "        description = medical_ai_task[\"description\"]\n",
    "        add_instruction = medical_ai_task[\"additional_instruction\"]\n",
    "        for profession in professions_data:\n",
    "            main_profession = profession[\"profession\"]\n",
    "            for specialty in profession[\"specialties\"]:\n",
    "                demographics = get_demographics()\n",
    "                for dem in demographics:\n",
    "                    prompt = get_prompt(task, description, add_instruction, subtopic)\n",
    "                    prompt_id = str(id)\n",
    "                    line = fill_line()\n",
    "                    file.write(json.dumps(line) + '\\n')\n",
    "                    id += 1\n",
    "        for profession in professions_data:\n",
    "            prompt = get_prompt()\n",
    "            prompt_id = str(id)\n",
    "            line = fill_line()\n",
    "            file.write(json.dumps(line) + '\\n')\n",
    "            id += 1\n",
    "        for topic in topics_data:\n",
    "            prompt = get_prompt()\n",
    "            prompt_id = str(id)\n",
    "            line = fill_line()\n",
    "            file.write(json.dumps(line) + '\\n')\n",
    "            id += 1\n",
    "\n",
    "print(f\"batch of {id} prompts saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ihlqa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
