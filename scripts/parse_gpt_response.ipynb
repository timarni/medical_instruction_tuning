{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 -> specialties x domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:00<00:00, 5132.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context of size 6321 of generated prompts saved in context dictionary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get context of generated prompt based on id\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Path for input data and to store prompts\n",
    "path_medical_settings = \"../results/medical_settings.json\"\n",
    "path_medical_subtopics = \"../results/medical_subtopics.json\"\n",
    "path_medical_professions = \"../results/medical_professions.json\"\n",
    "\n",
    "# Load data\n",
    "with open(path_medical_settings, \"r\") as f:\n",
    "    medical_settings = json.load(f)\n",
    "with open(path_medical_subtopics, \"r\") as f:\n",
    "    medical_subtopics = json.load(f)\n",
    "with open(path_medical_professions, \"r\") as f:\n",
    "    medical_professions = json.load(f)\n",
    "\n",
    "contexts = {}\n",
    "id = 0\n",
    "for prof_entry in tqdm(medical_professions):\n",
    "    profession = prof_entry[\"profession\"]\n",
    "    specialties = prof_entry[\"specialties\"]\n",
    "    for top_entry in medical_subtopics:\n",
    "        domain = top_entry[\"domain\"]\n",
    "        subtopics = top_entry[\"subtopic\"]\n",
    "        for specialty in specialties:\n",
    "            # for subtopic in subtopics: -> TODO: removed because gives too much prompts\n",
    "            contexts[id] = profession + \", \" + specialty + \", \" + domain\n",
    "            id += 1\n",
    "\n",
    "print(f\"Contexts of size {id} of generated prompts saved in contexts dictionary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse the string and create a JSON object\n",
    "def parse_gpt_response(string, id, contexts):\n",
    "    \"\"\"\n",
    "    Helper function fur parse_results()\n",
    "    Parses the gpt responses from string to dict\n",
    "    \"\"\"\n",
    "# Create a dictionary to hold the data in the desired format\n",
    "# Only successfull if all that is expected is present\n",
    "\n",
    "    try:\n",
    "        # Attempt to load the JSON string\n",
    "        # TODO: verify that gpt_response is like that\n",
    "\n",
    "        # Decode any UTF-8 character codes in the input string\n",
    "        decoded_string = (string.encode().decode('unicode_escape')).encode('latin1').decode('utf-8')\n",
    "\n",
    "        data_dict = {}\n",
    "        data_dict[\"id\"] = int(id)\n",
    "        data_dict[\"prompt\"] = decoded_string\n",
    "        data_dict[\"context\"] = contexts[int(id)]\n",
    "        return data_dict\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing GPT responses...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6321it [00:00, 45962.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medical prompts have been saved to ../results/parsed_health_care_worker_prompts.json\n",
      "See an example below:\n",
      "{\n",
      "    \"id\": 6320,\n",
      "    \"prompt\": \"\\\"What preventive strategies can be recommended for a patient who is at risk of depression due to prolonged physical rehabilitation, to improve their mental resilience and overall mental health?\\\"\",\n",
      "    \"context\": \"Clinical Psychologist, Rehabilitation Psychology, Preventive Medicine\"\n",
      "}\n",
      "Failed to parse 0 questions:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "path_to_results = \"../results/gpt_results.jsonl\"\n",
    "output_path = \"../results/parsed_health_care_worker_prompts.json\"\n",
    "\n",
    "\n",
    "# TODO: do both in the same for loop, no need to store contents\n",
    "# Extract content from json\n",
    "print(\"Parsing GPT responses...\")\n",
    "medical_prompts = []\n",
    "questions_failed_to_parse = []\n",
    "with open(path_to_results, 'r') as file:\n",
    "    for line in tqdm(file):\n",
    "        try:\n",
    "            data = json.loads(line)  # Parse each line as JSON\n",
    "            response_content = data.get(\"response\", {}).get(\"body\", {}).get(\"choices\", [])[0].get(\"message\", {}).get(\"content\", None)\n",
    "            id = data.get(\"custom_id\") # format \"1\"\n",
    "            if response_content and id:\n",
    "                parsed_response = parse_gpt_response(response_content, id, contexts)\n",
    "                if bool(parsed_response):\n",
    "                    medical_prompts.append(parsed_response)\n",
    "                else:\n",
    "                    questions_failed_to_parse.append(id)\n",
    "        except json.JSONDecodeError as e:\n",
    "            questions_failed_to_parse.append(id)\n",
    "print(\"Parsing completed\")\n",
    "\n",
    "# Save to JSON file\n",
    "with open(output_path, 'w') as json_file:\n",
    "    json.dump(medical_prompts, json_file, indent=4)\n",
    "\n",
    "# Output the parsed data (for verification)\n",
    "print(f\"Medical prompts have been saved to {output_path}\")\n",
    "print(\"See an example below:\")\n",
    "print(json.dumps(parsed_response, indent=4))\n",
    "print(f\"Failed to parse {len(questions_failed_to_parse)} questions:\")\n",
    "print(questions_failed_to_parse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 - ai_tasks x subtopics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load files necessary for context and store them in lists\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Path for input data and to store prompts\n",
    "medical_ai_tasks_file = \"../results/medical_ai_tasks.json\"\n",
    "subtopics_file = \"../results/medical_subtopics.json\"\n",
    "\n",
    "# store medical AI tasks in a list\n",
    "with open(medical_ai_tasks_file, 'r') as file:\n",
    "    medical_ai_tasks = json.load(file)  # Load JSON data from file\n",
    "\n",
    "# store subtopics in a list\n",
    "with open(subtopics_file, 'r') as file:\n",
    "    subtopics_data = json.load(file)  # Load JSON data from file\n",
    "\n",
    "# Extract subtopics\n",
    "subtopics = []\n",
    "for item in subtopics_data:\n",
    "    subtopics.extend(item['subtopic'])  # Add each subtopic list to the main list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse the string and create a JSON object\n",
    "def parse_gpt_response_2(string, task_id, subtopic_id, medical_ai_tasks, subtopics):\n",
    "    \"\"\"\n",
    "    Helper function fur parse_results()\n",
    "    Parses the gpt responses from string to dict\n",
    "    \"\"\"\n",
    "# Create a dictionary to hold the data in the desired format\n",
    "# Only successfull if all that is expected is present\n",
    "\n",
    "    try:\n",
    "        # Attempt to load the JSON string\n",
    "        # TODO: verify that gpt_response is like that\n",
    "\n",
    "        # Decode any UTF-8 character codes in the input string\n",
    "        decoded_string = (string.encode().decode('unicode_escape')).encode('latin1').decode('utf-8')\n",
    "\n",
    "        data_dict = {}\n",
    "        data_dict[\"id\"] = (task_id, subtopic_id)\n",
    "        data_dict[\"prompt\"] = decoded_string\n",
    "        data_dict[\"context\"] = medical_ai_tasks[task_id][\"task\"] + \", \" + subtopics[subtopic_id]\n",
    "        return data_dict\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "path_to_results = \"../results/gpt_results.jsonl\"\n",
    "output_path = \"../results/parsed_prompts_tasks_x_subtopics.json\"\n",
    "\n",
    "\n",
    "# TODO: do both in the same for loop, no need to store contents\n",
    "# Extract content from json\n",
    "print(\"Parsing GPT responses...\")\n",
    "medical_prompts = []\n",
    "questions_failed_to_parse = []\n",
    "with open(path_to_results, 'r') as file:\n",
    "    for line in tqdm(file):\n",
    "        try:\n",
    "            data = json.loads(line)  # Parse each line as JSON\n",
    "            response_content = data.get(\"response\", {}).get(\"body\", {}).get(\"choices\", [])[0].get(\"message\", {}).get(\"content\", None)\n",
    "            id = data.get(\"custom_id\") # format \"0-0\" \"task_id - subtopic_id\"\n",
    "            if response_content and id:\n",
    "                parsed_response = parse_gpt_response_2(response_content, int(id.split(\"-\")[0]), int(id.split(\"-\")[1]), medical_ai_tasks, subtopics)\n",
    "                if bool(parsed_response):\n",
    "                    medical_prompts.append(parsed_response)\n",
    "                else:\n",
    "                    questions_failed_to_parse.append(id)\n",
    "        except json.JSONDecodeError as e:\n",
    "            questions_failed_to_parse.append(id)\n",
    "print(\"Parsing completed\")\n",
    "\n",
    "# Save to JSON file\n",
    "with open(output_path, 'w') as json_file:\n",
    "    json.dump(medical_prompts, json_file, indent=4)\n",
    "\n",
    "# Output the parsed data (for verification)\n",
    "print(f\"Medical prompts have been saved to {output_path}\")\n",
    "print(\"See an example below:\")\n",
    "print(json.dumps(parsed_response, indent=4))\n",
    "print(f\"Failed to parse {len(questions_failed_to_parse)} questions:\")\n",
    "print(questions_failed_to_parse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ihlqa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
