{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Entry:\n",
      "id: B-2218-2A-Central African Republic\n",
      "nbr_of_turns: 3\n",
      "initial_prompt: In the Central African Republic, an 8-month-old female is brought in with high fever, persistent crying, and refusal to feed. She also has a bulging fontanelle and is lethargic. Given these symptoms, can you guide me on how to prioritize this case and what immediate interventions should be considered?\n",
      "Answer in bullet points.\n",
      "system_prompt_chatbot: You are a medical AI chatbot designed to assist health care workers working in Central African Republic by answering their questions. \n",
      "The style of your answers must follow these rules: \n",
      "- Respectful, polite interaction: You must always engage in a respectful, polite, and courteous manner, maintaining professionalism in all interactions.\n",
      "- Honest, evidence-based information: All responses have to be based on the latest medical evidence and guidelines\n",
      "- Ethical and safe content: Under no circumstances should you provide fake, harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. If a question is unclear or factually incorrect, you should explain why rather than attempting to answer it inaccurately.\n",
      "- Dosage: If asked about dosage medication, provide a ballpark estimate of the dosage but always provide a concise warning that this should be checked in the form of “(dosages should be verified)”.\n",
      "- Adhere meticulously to any specific formatting instructions provided by the user in the prompt, ensuring the generated output aligns precisely with their requirements.\n",
      "- Tailor responses to the geographical context, resource setting, level of care, seasonality/epidemiology, and medical specialty as relevant.\n",
      "\n",
      "system_prompt_user: You are a Nurse specialized in Emergency Nursing working in Central African Republic using a medical AI chatbot to help you taking care of your patients. \n",
      "The initial question that you ask the medical AI chatbot has already been provided. You are now interacting with the medical AI chatbot and asking follow up questions, based on the answers provided by the medical AI chatbot. \n",
      "The style of the follow up question you ask must follow these rules: \n",
      "- Ask long and detailed questions. \n",
      "\n",
      "multiturn_style_parameters: ['normal', 'no_specification', 'no_specification', 'standard', 'long', 'standard', 'Nurse specialized in Emergency Nursing']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "def print_random_entry_from_jsonl(file_path):\n",
    "    \"\"\"\n",
    "    Reads a .jsonl file, selects an entry uniformly at random, and prints its fields.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the .jsonl file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            entries = [json.loads(line) for line in file]\n",
    "            \n",
    "            if not entries:\n",
    "                print(\"The file is empty.\")\n",
    "                return\n",
    "\n",
    "            random_entry = random.choice(entries)\n",
    "\n",
    "            print(\"Random Entry:\")\n",
    "            for key, value in random_entry.items():\n",
    "                print(f\"{key}: {value}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error decoding JSON. Please check the file format.\")\n",
    "\n",
    "# Example usage\n",
    "file_path = \"../results/situations_task_x_specialties_x_demographic_x_answerstyle_2.jsonl\"\n",
    "print_random_entry_from_jsonl(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file contains 20395 entries.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Function to load and count entries in a .json file\n",
    "def count_entries(file_path):\n",
    "    \"\"\"\n",
    "    Reads a .json file and counts the number of entries.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "        return len(data)\n",
    "\n",
    "file_path = \"../results/parsed_prompts_task_x_specialties_x_demographic_x_answerstyle_2.json\"  # Replace with the actual path to your .json file\n",
    "entry_count = count_entries(file_path)\n",
    "print(f\"The file contains {entry_count} entries.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of entries: 20395\n",
      "Number of prompts containing the word 'emergency': 973\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def count_entries_and_screen_for_emergency(json_file_path):\n",
    "    try:\n",
    "        with open(json_file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "\n",
    "            # Count the number of entries\n",
    "            total_entries = len(data)\n",
    "            print(f\"Total number of entries: {total_entries}\")\n",
    "\n",
    "            # Screen for the word 'emergency' in the prompt and count matches\n",
    "            emergency_count = sum('emergency' in entry['prompt'].lower() for entry in data)\n",
    "            print(f\"Number of prompts containing the word 'emergency': {emergency_count}\")\n",
    "\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        print(\"Error: Unable to read or parse the JSON file.\")\n",
    "\n",
    "json_file_path = \"../results/parsed_prompts_task_x_specialties_x_demographic_x_answerstyle_2.json\"\n",
    "count_entries_and_screen_for_emergency(json_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: A-1092-3F-North Macedonia\n",
      "Prompt: How can I explain the condition of plantar fasciitis to a 35-year-old female patient in North Macedonia, in simple terms, including why it causes heel pain and what treatment options, such as stretching exercises or orthotics, are available to manage the condition?\n",
      "In your answer highlight the risks and benefits.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "# Load the .json file\n",
    "def load_json(file_path):\n",
    "    \"\"\"\n",
    "    Loads a .json file and returns its content as a list of dictionaries.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        return json.load(file)\n",
    "\n",
    "# Randomly sample an entry and extract id and prompt\n",
    "def sample_entry(json_data):\n",
    "    \"\"\"\n",
    "    Randomly samples an entry from the JSON data and extracts the id and prompt.\n",
    "    \"\"\"\n",
    "    sampled_entry = random.choice(json_data)\n",
    "    \n",
    "    # Extract id\n",
    "    entry_id = sampled_entry.get(\"id\", \"N/A\")\n",
    "\n",
    "    # Extract prompt\n",
    "    prompt = sampled_entry.get(\"prompt\", \"N/A\")\n",
    "\n",
    "    return entry_id, prompt\n",
    "\n",
    "file_path = \"../results/parsed_prompts_task_x_specialties_x_demographic_x_answerstyle_2.json\"  # Replace with the actual path to your .json file\n",
    "json_data = load_json(file_path)\n",
    "\n",
    "# Sample an entry and print the id and prompt\n",
    "entry_id, prompt = sample_entry(json_data)\n",
    "print(f\"ID: {entry_id}\\nPrompt: {prompt}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Elderly',\n",
       " 'Centenarians',\n",
       " 'Older Adults',\n",
       " 'Preschoolers',\n",
       " 'Toddlers',\n",
       " 'School-age Children',\n",
       " 'Infants',\n",
       " 'Adolescents',\n",
       " 'Infants',\n",
       " 'Adolescents',\n",
       " 'Adults',\n",
       " 'Middle-aged Adults',\n",
       " 'Older Adults',\n",
       " 'Elderly',\n",
       " 'Elderly',\n",
       " 'Elderly',\n",
       " 'Elderly',\n",
       " 'Preschoolers',\n",
       " 'Infants',\n",
       " 'School-age Children',\n",
       " 'Young Adults',\n",
       " 'Infants',\n",
       " 'School-age Children',\n",
       " 'Adults',\n",
       " 'Centenarians',\n",
       " 'Young Adults',\n",
       " 'Infants',\n",
       " 'Toddlers',\n",
       " 'Preschoolers',\n",
       " 'Middle-aged Adults']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "age_ranges_file = \"../resources/age_categories.json\"\n",
    "# store age ranges in a list\n",
    "with open(age_ranges_file, 'r') as file:\n",
    "    age_ranges = json.load(file)  # Load JSON data from file\n",
    "ages = [dict[\"category\"] for dict in age_ranges]\n",
    "random.choices(ages, k=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Oman',\n",
       " 'Greece',\n",
       " 'Uganda',\n",
       " 'Ethiopia',\n",
       " 'Uzbekistan',\n",
       " 'El Salvador',\n",
       " 'Thailand',\n",
       " 'Mauritius']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "countries_file = \"../resources/countries_by_income_category.csv\"\n",
    "countries = pd.read_csv(countries_file)\n",
    "\n",
    "# Step 1: Group by 'Income Category'\n",
    "groups = countries.groupby(\"Income Category\")\n",
    "\n",
    "# Step 2: Ensure at least two groups are available\n",
    "if len(groups) < 2:\n",
    "    raise ValueError(\"Not enough unique income categories to sample from.\")\n",
    "\n",
    "# Step 3: Randomly sample one country from two different categories\n",
    "sampled_countries = []\n",
    "for category, group in groups:\n",
    "    sampled_countries.append(group.sample(n=2))\n",
    "sampled_countries_df = pd.concat(sampled_countries).reset_index(drop=True)\n",
    "sampled_countries_df[\"Country\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Allergy and Immunology', 'Anesthesiology', 'Cardiology', 'Dermatology', 'Emergency Medicine', 'Endocrinology', 'Family Medicine', 'Gastroenterology', 'Geriatrics', 'Hematology', 'Infectious Disease', 'Internal Medicine', 'Nephrology', 'Neurology', 'Obstetrics and Gynecology', 'Oncology', 'Ophthalmology', 'Orthopedic Surgery', 'Otolaryngology (ENT)', 'Pathology', 'Pediatrics', 'Physical Medicine and Rehabilitation', 'Psychiatry', 'Pulmonology', 'Radiology', 'Rheumatology', 'Surgery', 'Urology']\n",
      "['Critical Care Nursing', 'Emergency Nursing', 'Geriatric Nursing', 'Medical-Surgical Nursing', 'Neonatal Nursing', 'Oncology Nursing', 'Pediatric Nursing', 'Psychiatric Nursing', 'Public Health Nursing']\n",
      "['Family Medicine', 'Emergency Medicine', 'Surgery', 'Dermatology', 'Orthopedics', 'Psychiatry']\n",
      "['Clinical Pharmacy', 'Community Pharmacy', 'Consultant Pharmacy', 'Hospital Pharmacy', 'Industrial Pharmacy', 'Nuclear Pharmacy', 'Oncology Pharmacy']\n",
      "['Cardiovascular and Pulmonary', 'Geriatric', 'Neurological', 'Orthopedic', 'Pediatric', 'Sports', \"Women's Health\"]\n",
      "['Geriatric Occupational Therapy', 'Mental Health Occupational Therapy', 'Pediatric Occupational Therapy', 'Physical Rehabilitation', 'Hand Therapy']\n",
      "['Fluency Disorders', 'Neurogenic Communication Disorders', 'Speech Sound Disorders', 'Voice Disorders', 'Swallowing Disorders']\n",
      "['Diagnostic Radiology', 'Computed Tomography (CT)', 'Magnetic Resonance Imaging (MRI)', 'Nuclear Medicine', 'Ultrasound', 'Mammography']\n",
      "['Clinical Chemistry', 'Hematology', 'Immunology', 'Microbiology', 'Molecular Diagnostics', 'Transfusion Medicine']\n",
      "['Clinical Dietetics', 'Community Dietetics', 'Foodservice Management', 'Gerontological Nutrition', 'Pediatric Nutrition', 'Sports Nutrition']\n",
      "['Adult Critical Care', 'Neonatal and Pediatric Care', 'Pulmonary Rehabilitation', 'Sleep Disorders']\n",
      "['Emergency Medical Services', 'Critical Care Transport', 'Tactical EMS', 'Community Paramedicine']\n",
      "['Sports Chiropractic', 'Pediatric Chiropractic', 'Geriatric Chiropractic', 'Rehabilitation']\n",
      "['Podiatric Surgery', 'Sports Medicine', 'Diabetic Foot Care', 'Pediatric Podiatry']\n",
      "['Pediatric Optometry', 'Geriatric Optometry', 'Vision Therapy', 'Contact Lens Specialist']\n",
      "['Pediatric Audiology', 'Cochlear Implants', 'Balance Disorders', 'Hearing Aid Dispensing']\n",
      "['Industrial Hygiene', 'Ergonomics', 'Risk Management']\n",
      "['Clinical Social Work', 'Healthcare Administration', 'Mental Health Counseling', 'Palliative Care']\n",
      "['Prenatal Genetics', 'Cancer Genetics', 'Pediatric Genetics', 'Cardiovascular Genetics']\n",
      "['Lower Limb Prosthetics', 'Upper Limb Prosthetics', 'Spinal Orthotics', 'Pediatric Prosthetics and Orthotics']\n",
      "['Child and Adolescent Psychology', 'Neuropsychology', 'Health Psychology', 'Forensic Psychology', 'Rehabilitation Psychology']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "path_to_file1 = \"../resources/patient_age_medical_profession.json\"  # Replace with your desired output file name\n",
    "path_to_file2 = \"../resources/medical_professions.json\"  # Replace with your desired output file name\n",
    "\n",
    "\n",
    "with open(path_to_file1, 'r') as file:\n",
    "    data1 = json.load(file)\n",
    "\n",
    "with open(path_to_file2, 'r') as file:\n",
    "    data2 = json.load(file)\n",
    "\n",
    "for dict1, dict2 in zip(data1, data2):\n",
    "    list_dict1 = [element[0] for element in dict1[\"specialties\"]]\n",
    "    if dict2[\"specialties\"] == list_dict1:\n",
    "        print(list_dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def process_file(input_file, output_file):\n",
    "    data = []\n",
    "    current_profession = None\n",
    "    specialties = []\n",
    "\n",
    "    with open(input_file, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "\n",
    "            # Skip empty lines\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            # Process profession (### lines)\n",
    "            if line.startswith(\"###\"):\n",
    "                if current_profession:\n",
    "                    # Save the previous profession and its specialties\n",
    "                    data.append({\n",
    "                        \"profession\": current_profession,\n",
    "                        \"specialties\": specialties\n",
    "                    })\n",
    "                # Extract profession name\n",
    "                current_profession = line.replace(\"###\", \"\").strip(\" **\")\n",
    "                specialties = []\n",
    "            \n",
    "            # Process specialties (lines starting with numbers)\n",
    "            elif line[0].isdigit():\n",
    "                # Extract specialty name and age categories\n",
    "                specialty, age_categories = line.split(\":\")\n",
    "                specialty = specialty.strip().split(\". \")[1].replace(\"*\", \"\")  # Remove number\n",
    "                age_categories = [age.strip() for age in age_categories.split(\",\")]\n",
    "                specialties.append([specialty, age_categories])\n",
    "\n",
    "    # Add the last profession to data\n",
    "    if current_profession:\n",
    "        data.append({\n",
    "            \"profession\": current_profession,\n",
    "            \"specialties\": specialties\n",
    "        })\n",
    "\n",
    "    # Write the data to a JSON file\n",
    "    with open(output_file, 'w') as json_file:\n",
    "        json.dump(data, json_file, indent=2)\n",
    "\n",
    "# Usage\n",
    "input_file = \"../resources/patient_age_medical_profession.txt\"  # Replace with your input file name\n",
    "output_file = \"../resources/patient_age_medical_profession.json\"  # Replace with your desired output file name\n",
    "process_file(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File '../results/multiturn_tasks_x_subtopics.jsonl' updated successfully!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Define the file path\n",
    "file_path = '../results/multiturn_tasks_x_subtopics.jsonl'\n",
    "\n",
    "# Function to replace Unicode escape sequences with real characters\n",
    "def replace_unicode_in_jsonl(file_path):\n",
    "    try:\n",
    "        # Read the file and decode Unicode escape sequences\n",
    "        updated_lines = []\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                entry = json.loads(line)  # Parse JSON\n",
    "                entry_str = json.dumps(entry, ensure_ascii=False)  # Convert to string with real characters\n",
    "                updated_lines.append(entry_str)\n",
    "        \n",
    "        # Write the updated content back to the same file\n",
    "        with open(file_path, 'w', encoding='utf-8') as file:\n",
    "            file.write('\\n'.join(updated_lines))\n",
    "        \n",
    "        print(f\"File '{file_path}' updated successfully!\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{file_path}' not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Run the function\n",
    "replace_unicode_in_jsonl(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sentence_transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mumap\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhdbscan\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sentence_transformers'"
     ]
    }
   ],
   "source": [
    "# Script to convert prompts into embeddings and cluster them\n",
    "# Script from Bastien\n",
    "\n",
    "import os\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import umap\n",
    "import hdbscan\n",
    "import numpy as np\n",
    "data = []\n",
    "\n",
    "name_of_prompts = \"task_x_subtopics\"\n",
    "path_to_prompts = \"../results/parsed_prompts_\" + name_of_prompts + \".json\"\n",
    "path_to_embeddings = \"../clustering/embeddings_pp_\" + name_of_prompts + \".npy\"\n",
    "\n",
    "# Control test mode\n",
    "test_mode = True  # Set to False to load all data\n",
    "\n",
    "# Load prompts\n",
    "with open(path_to_prompts, 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if test_mode and i >= 5:  # Only load first 5 entries in test mode\n",
    "            break\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "questions = []\n",
    "for d in data:\n",
    "    questions.append(d['prompt'])\n",
    "\n",
    "\n",
    "if os.path.exists(path_to_embeddings):\n",
    "    with open(path_to_embeddings, 'rb') as f:\n",
    "        embeddings = np.load(f)\n",
    "else:\n",
    "    embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    embeddings = embedder.encode(questions, show_progress_bar=True)\n",
    "\n",
    "    with open(path_to_embeddings, 'wb') as f:\n",
    "        np.save(f, embeddings)\n",
    "\n",
    "# Reduce dimensionality to 5 or 10 dimensions\n",
    "umap_reducer = umap.UMAP(n_components=5, random_state=42)\n",
    "reduced_embeddings = umap_reducer.fit_transform(embeddings)\n",
    "\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=5, min_samples=1, metric='euclidean')\n",
    "cluster_labels = clusterer.fit_predict(reduced_embeddings)\n",
    "\n",
    "# Print the clusters and their associated sentences\n",
    "num_clusters = len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0)  # Exclude noise label (-1)\n",
    "print(f\"Number of clusters found: {num_clusters}\")\n",
    "\n",
    "print(\"I found that the users often ask about the same thing, I don't know what to do with this information, maybe we only use one question per cluster ? We'll see, but first interesting thing to note\")\n",
    "# Print sentences grouped by clusters\n",
    "for cluster in range(num_clusters):\n",
    "    # Find indices of elements belonging to the current cluster\n",
    "    cluster_indices = [i for i, label in enumerate(cluster_labels) if label == cluster]\n",
    "    \n",
    "    # Only print out small clusters\n",
    "    if len(cluster_indices) <= 4:\n",
    "        print(f\"Cluster {cluster} (size: {len(cluster_indices)}):\")\n",
    "        for i in cluster_indices:\n",
    "            print(f\" - {questions[i]}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reduce to 2D for visualization\n",
    "umap_2d = umap.UMAP(n_components=2, random_state=42)\n",
    "embedding_2d = umap_2d.fit_transform(embeddings)\n",
    "\n",
    "# Plot clusters\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(embedding_2d[:, 0], embedding_2d[:, 1], c=cluster_labels, cmap='Spectral', s=50)\n",
    "plt.colorbar()\n",
    "plt.title(\"Sentence Clusters based on Sentence Embeddings (I haven't found this useful honestly)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bastien Code for inspiration -> Multiturn\n",
    "\n",
    "def system_prompt(self, final=False) -> str:\n",
    "\n",
    "        # First sentence options\n",
    "        # Updated first sentence options\n",
    "        if self.brief:\n",
    "            first_sentence_options = [\n",
    "                \"As a doctor in {}, you are in {} Your task is to diagnose a patient by asking concise questions and providing brief reasoning. Keep your explanations short and to the point, and ask pertinent questions.\",\n",
    "                \"You are practicing medicine in {}. {} Your mission is to determine the patient's diagnosis through concise inquiry, being efficient in your thought process. Make your thinking clear but succinct, then pose relevant questions.\",\n",
    "                \"While working as a physician in {}, {} Your role is to identify the patient's ailment by asking concise questions and efficiently analyzing your thoughts. Be explicit yet brief in your reasoning, and ask appropriate questions.\",\n",
    "                \"In {}, you find yourself in {} Your task is to diagnose a patient by asking concise questions and providing brief reasoning. Keep your explanations short and to the point, and ask pertinent questions.\",\n",
    "                \"Serving as a doctor in {}, {} Your mission is to determine the patient's diagnosis through concise inquiry, being efficient in your thought process. Make your thinking clear but succinct, then pose relevant questions.\",\n",
    "                \"As a physician in {}, you are confronted with {} Your role is to identify the patient's ailment by asking concise questions and efficiently analyzing your thoughts. Be explicit yet brief in your reasoning, and ask appropriate questions.\",\n",
    "            ]\n",
    "        elif self.bullet:\n",
    "            first_sentence_options = [\n",
    "                \"As a doctor in {}, you are in {} Your task is to diagnose a patient by asking concise questions and providing brief reasoning. Be explicit and to the point, present your reasoning and questions in bullet points.\",\n",
    "                \"You are practicing medicine in {}. {} Your mission is to determine the patient's diagnosis through concise inquiry, being efficient in your thought process. Make your thinking clear and format your reasoning and questions as bullet points.\",\n",
    "                \"While working as a physician in {}, {} Your role is to identify the patient's ailment by asking concise questions and efficiently analyzing your thoughts. Be explicit and present your questions and reasoning in bullet points.\",\n",
    "                \"In {}, you find yourself in {} Your task is to diagnose a patient by asking concise questions and providing brief reasoning. Make your thinking clear and use bullet points to present your reasoning and questions.\",\n",
    "                \"Serving as a doctor in {}, {} Your mission is to determine the patient's diagnosis through concise inquiry, being efficient in your thought process. Make your thinking clear and present your reasoning and questions in bullet points.\",\n",
    "                \"As a physician in {}, you are confronted with {} Your role is to identify the patient's ailment by asking concise questions and efficiently analyzing your thoughts. Be explicit and format your reasoning and questions as bullet points.\",\n",
    "            ]\n",
    "        else:\n",
    "            first_sentence_options = [\n",
    "                \"As a doctor in {}, you are in {} Your task is to diagnose a patient by asking questions and carefully considering your thoughts. Explain your reasoning and ask pertinent questions.\",\n",
    "                \"You are practicing medicine in {}. {} Your mission is to determine the patient's diagnosis through inquiry, being thorough in your thought process. Make your thinking explicit, then pose relevant questions.\",\n",
    "                \"While working as a physician in {}, {} Your role is to identify the patient's ailment by asking questions and thoroughly analyzing your thoughts. Be explicit about your reasoning, and ask appropriate questions.\",\n",
    "                \"In {}, you find yourself in {} Your task is to diagnose a patient by asking questions and carefully considering your thoughts. Explain your reasoning and ask pertinent questions.\",\n",
    "                \"Serving as a doctor in {}, {} Your mission is to determine the patient's diagnosis through inquiry, being thorough in your thought process. Make your thinking explicit, then pose relevant questions.\",\n",
    "                \"As a physician in {}, you are confronted with {} Your role is to identify the patient's ailment by asking questions and thoroughly analyzing your thoughts. Be explicit about your reasoning, and ask appropriate questions.\",\n",
    "            ]\n",
    "\n",
    "        first_sentence = random.choice(first_sentence_options).format(self.country, random.choice(setting_doctor[self.setting]))\n",
    "\n",
    "        # Test request sentence for high resource setting\n",
    "        if self.setting == \"high\" and self.infs < self.MAX_INFS:\n",
    "            test_request_options = [\n",
    "                \"You may also request tests if they are available and can assist in your diagnosis, using the format \\\"REQUEST TEST: [test]\\\". For instance, \\\"REQUEST TEST: Chest_X-Ray\\\".\",\n",
    "                \"If helpful and accessible, you should request tests to aid your diagnosis using the format \\\"REQUEST TEST: [test]\\\". Example: \\\"REQUEST TEST: Chest_X-Ray\\\".\",\n",
    "                \"Feel free to request any available tests that might help in diagnosing, using \\\"REQUEST TEST: [test]\\\". For example, \\\"REQUEST TEST: Chest_X-Ray\\\".\",\n",
    "            ]\n",
    "            test_request_sentence = random.choice(test_request_options)\n",
    "        else:\n",
    "            test_request_sentence = \"\"\n",
    "\n",
    "        # Question limit sentence options\n",
    "        if final:\n",
    "            question_limit_options = [\n",
    "                \"You are only allowed to ask {} questions in total before you must make a decision.\",\n",
    "                \"You have a limit of {} questions to ask before making a diagnosis.\",\n",
    "                \"You can ask up to {} questions before you need to decide.\",\n",
    "                \"You may ask a maximum of {} questions before diagnosing.\",\n",
    "                \"A total of {} questions are allowed before you must diagnose.\",\n",
    "                \"You have {} questions in total to reach your diagnosis.\",\n",
    "                \"Only {} questions can be asked before making your decision.\",\n",
    "                \"You are permitted to ask up to {} questions before you must decide.\",\n",
    "            ]\n",
    "            question_limit_sentence = random.choice(question_limit_options).format(self.MAX_INFS)\n",
    "        else:\n",
    "            question_limit_options = [\n",
    "                \"You are only allowed to ask {} questions in total before you must make a decision. You have asked {} questions so far.\",\n",
    "                \"You have a limit of {} questions to ask before making a diagnosis. So far, you've asked {} questions.\",\n",
    "                \"You can ask up to {} questions before you need to decide. Currently, you have asked {} questions.\",\n",
    "                \"You may ask a maximum of {} questions before diagnosing. You have already asked {} questions.\",\n",
    "                \"A total of {} questions are allowed before you must diagnose. Up to now, you've asked {} questions.\",\n",
    "                \"You have {} questions in total to reach your diagnosis. So far, you've used {} questions.\",\n",
    "                \"Only {} questions can be asked before making your decision. You have asked {} questions till now.\",\n",
    "                \"You are permitted to ask up to {} questions before you must decide. At present, you have asked {} questions.\",\n",
    "            ]\n",
    "            question_limit_sentence = random.choice(question_limit_options).format(self.MAX_INFS, self.infs)\n",
    "        \n",
    "\n",
    "        # Diagnosis instruction options\n",
    "        diagnosis_instruction_options = [\n",
    "            \"Once you have decided to make a diagnosis, please type \\\"DIAGNOSIS READY: [diagnosis here]\\\".\",\n",
    "            \"When ready to diagnose, enter \\\"DIAGNOSIS READY: [diagnosis here]\\\".\",\n",
    "            \"After concluding your diagnosis, submit it using \\\"DIAGNOSIS READY: [diagnosis here]\\\".\",\n",
    "            \"Upon reaching a diagnosis, please type \\\"DIAGNOSIS READY: [diagnosis here]\\\".\",\n",
    "            \"Once you are confident in your diagnosis, enter \\\"DIAGNOSIS READY: [diagnosis here]\\\".\",\n",
    "            \"When you have determined the diagnosis, submit it using \\\"DIAGNOSIS READY: [diagnosis here]\\\".\",\n",
    "            \"After you have made a diagnosis, indicate it by typing \\\"DIAGNOSIS READY: [diagnosis here]\\\".\",\n",
    "            \"When you are prepared to diagnose, please provide it using \\\"DIAGNOSIS READY: [diagnosis here]\\\".\",\n",
    "        ]\n",
    "        diagnosis_instruction_sentence = random.choice(diagnosis_instruction_options)\n",
    "\n",
    "        # Knows diagnosis sentence\n",
    "        if self.knows_diagnosis and not final:\n",
    "            knows_diagnosis_options = [\n",
    "                \" You suspect that the patient suffers from {}. This affects the questions you ask the patient.\",\n",
    "                \" You have a hunch that the patient may have {}. This should influence your questioning.\",\n",
    "                \" You believe the patient might be suffering from {}. Let this guide your questions.\",\n",
    "            ]\n",
    "            knows_diagnosis_sentence = random.choice(knows_diagnosis_options).format(self.correct_diagnosis)\n",
    "        else:\n",
    "            knows_diagnosis_sentence = \"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ihlqa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
